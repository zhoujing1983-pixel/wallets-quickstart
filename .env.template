NEXT_PUBLIC_FINYX_API_KEY= # Crossmint client API key (public)

# Check all supported chains: https://docs.crossmint.com/introduction/supported-chains
NEXT_PUBLIC_CHAIN="solana" # "base-sepolia", "stellar", etc.

# Bank transfer configuration for withdraw
NEXT_PUBLIC_CROSSMINT_BANK_ACCOUNT_REF= # Bank account reference for withdraw

# Server-side API key used by backend routes
CROSSMINT_SERVER_SIDE_API_KEY= # Crossmint server API key (private)
CROSSMINT_ENV="staging" # use "production" when calling against production Crossmint
ONRAMP_COOKIE_SECRET= # secret used to sign onramp cookies

# Provider receive address for WaaS payment demo
NEXT_PUBLIC_PROVIDER_WALLET= # provider receive address for WaaS payment demo

# Receipt signing secret for Billing -> Provider verification
BILLING_RECEIPT_SECRET= # secret for receipt signing

# Authorization signing secret for intent/delegation proofs
BILLING_AUTH_SECRET= # secret for intent/delegation proofs

# Solana RPC for memo-based authorization (used when chain=solana)
SOLANA_RPC_URL="https://api.devnet.solana.com" # server-side RPC

# Expose Solana RPC to client UI diagnostics (optional)
NEXT_PUBLIC_SOLANA_RPC_URL="https://api.devnet.solana.com" # exposed to client diagnostics

# Google AI
GOOGLE_GENERATIVE_AI_API_KEY= # Google AI key (optional)
GOOGLE_MODEL=gemini-2.5-flash # gemini-1.5, gemini-2, gemini-2.5-flash, gemini-2.5-flash-lite

# Optional local model settings
MODEL_PROVIDER="qwen" # "ollama" | "lmstudio" | "google"
OLLAMA_MODEL=llama3.2:1b # TinyLlama | Llama3.2:1b | Llama3:7b | Llama3:13b | Llama3:70b
LM_STUDIO_MODEL=qwen/qwen3-1.7b # local LM Studio chat model
LM_STUDIO_EMBEDDING_MODEL=Qwen/Qwen3-Embedding-0.6B-GGUF # local embeddings
LM_STUDIO_BASE_URL="http://localhost:1234/v1" # LM Studio OpenAI-compatible endpoint
LM_STUDIO_TEMPERATURE=0.7 # only for LM Studio provider
LM_STUDIO_MAX_TOKENS=-1 # -1 means provider default
LM_STUDIO_NO_THINK=false # disable think mode for LM Studio if supported

# Think-capable models (server-side, used for showing Think toggle in chat)
AGENT_THINK_MODELS=qwen/qwen3-4b,gemini-2.5-flash,qwen/qwen3-1.7b,qwen-plus # models that support "think" toggle

# VoltAgent instructions
VOLTAGENT_INSTRUCTIONS="You are a Web3 payments assistant. Keep responses brief."
VOLTAGENT_SERVER_PROMPT= # optional server-side system prompt override

# VoltAgent (Qwen via DashScope OpenAI-compatible API)
QWEN_API_KEY= # DashScope API key
QWEN_MODEL="qwen-plus" # Qwen chat model
QWEN_EMBEDDING_MODEL=text-embedding-v3 # Qwen embedding model
# Optional override for compatible-mode base URL
QWEN_BASE_URL="https://dashscope.aliyuncs.com/compatible-mode/v1"
# Optional override for compatible-mode base URL for international users
# QWEN_BASE_URL="https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
QWEN_REASONING_INSTRUCTION="思考过程请用中文输出。" # optional instruction for reasoning output

# Toggle whether VoltAgent should persist `<reason>` thinking blocks into memory (true/false).
VOLTAGENT_SAVE_REASONING_TO_MEMORY=true # persist <reason> blocks into memory

# SMTP for email OTP
SMTP_HOST= # SMTP host
SMTP_PORT=465
SMTP_USER=
SMTP_PASS=
SMTP_SECURE=true
MAIL_FROM= # sender email
CONTACT_TO= # optional contact email

# Redis url
REDIS_URL=redis://localhost:6379

# Postgres (docker-compose)
DATABASE_URL=postgres://admin:admin@localhost:5432/finyx
# OTP redis db (numeric, default 0)
OTP_REDIS_DB=1 # OTP redis db index
# Email queue switch (BullMQ)
EMAIL_QUEUE_ENABLED=true # enable BullMQ email queue
EMAIL_QUEUE_REDIS_DB=1

# Crossmint admin signer (if needed)
CROSSMINT_ADMIN_SIGNER_ADDRESS= # optional admin signer address
CROSSMINT_WALLET_ALIAS=server

# VoltAgent runtime
AGENT_PROXY_MODE="local-rag" # "local-rag", "hybrid", or "voltagent"
NEED_RAG=true
AGENT_SKILLS_DIR=./skills # local skills directory
AGENT_SKILL_DEBUG=true # log skill matching
# 工具调用策略（控制模型是否允许调用工具）：
# - auto：默认行为，允许工具调用（保持原逻辑）；
# - off：全局禁用工具调用；
# - rag-only：仅 ragMode=rag 时允许工具调用，ragMode=llm 时禁用。
AGENT_TOOL_CALL_POLICY=auto # "auto", "off", "rag-only"

# Local RAG
LOCAL_RAG_DB_PATH=./local-rag-vec.db # SQLite + sqlite-vec path
LOCAL_RAG_USE_LLM_SUMMARY=false # use LLM to summarize RAG hits
RAG_DISTANCE_THRESHOLD=0.9 # lower is stricter
RAG_INGEST_DIR=./rag-docs # folder to index
RAG_INGEST_EXTENSIONS=.md,.mdx,.txt,.ts,.tsx,.js,.jsx,.json,.pdf,.docx,.xlsx,.xls
RAG_INGEST_EXCLUDE=.git,.next,node_modules,dist,build,coverage,public
RAG_MAX_FILE_BYTES=200000
RAG_CHUNK_TOKENS=400
RAG_CHUNK_OVERLAP=60
RAG_TOP_K=4
RAG_FORCE_REINDEX=false
RAG_EMBEDDING_MODEL=text-embedding-v3
RAG_EMBEDDING_BATCH=10
# Duffel (sandbox)
DUFFEL_API_KEY=
# OurAirports paths
AIRPORTS_CSV_PATH=rag-docs/ourairports/airports.csv
AIRPORTS_INDEX_PATH=rag-docs/ourairports/airports-index.json
AIRPORTS_ALIAS_PATH=rag-docs/ourairports/city-aliases.json
AGENT_SKILL_INCLUDE_REFERENCES=false
